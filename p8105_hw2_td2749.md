p8105_hw2_td2749
================
Tvisha R. Devavarapu
2022-09-29

``` r
library(tidyverse)
```

## Problem 1: NYC Transit Data (Practice)

``` r
nyc_transit = 
  read_csv("data/nyc_transit.csv",
           col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), 
         entry, exit_only, vending, entrance_type, ada) %>%
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As is, there are 1868 observations across 20 variables. The data is not
fully tidy. The route number colums could be made into a single route
variable (pivot long).

``` r
nyc_transit %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

There are 465 unique stations.

``` r
nyc_transit %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

84 stations are ADA Compliant.

``` r
nyc_transit %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

Mean = 0.377

``` r
nyc_transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
nyc_transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

17

# Problem 2: Trash Wheel

The original Mr. Trash Wheel excel sheet consists of 550 rows and 14
columns. Upon examination of the entire ‘Mr. Trash Wheel’ sheet in the
newly updated file, I have realized that the required data is listed in
continuous rows with no unnecessary breaks that would hinder the
generation of a tidy/analysis-friendly sheet. Hence, I excluded the
first row (image) and last row (totals) of the original sheet, which
leaves us 548 rows including the first row with variable names. The
resultant sheet has 547 dumpster-specific rows and 15 columns of
variables (the last one is the identifier I have generated for the
binding purpose. (Note: I removed the drop_na(Dumpster) component which
was relevant for the earlier data set. As it is not serving any purpose
here due to lack of empty cells in the ‘dumpster’ column, I have deleted
it from the current code.)

``` r
mr_trash_wheel = 
  readxl::read_excel("data/new_t_w.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N549") %>%
  janitor::clean_names() %>%
  rename(weight_in_tons = weight_tons, volume_in_cubic_yards = volume_cubic_yards) %>%
  mutate(sports_balls = as.integer(round(sports_balls)))

mr_trash_wheel = mutate(mr_trash_wheel, identifier = rep("*", nrow(mr_trash_wheel)))
```

``` r
prof_trash_wheel = 
  readxl::read_excel("data/new_t_w.xlsx", sheet = "Professor Trash Wheel", range = "A2:M96") %>%
  janitor::clean_names() %>%
  rename(weight_in_tons = weight_tons, volume_in_cubic_yards = volume_cubic_yards) %>%
  mutate(year = as.character(year))

prof_trash_wheel = mutate(prof_trash_wheel, identifier = rep("#", nrow(prof_trash_wheel)))
```

``` r
trash_wheel_collective = 
  bind_rows(mr_trash_wheel, prof_trash_wheel)
```

The final dataset `trash_wheel_collective` consists of *641
observations* ranging across *15 columns*. 547 of the observations
pertain to unique dumpsters associated with Mr. Trash Wheel. The
remaining 94 observations pertain to the unique dumpsters associated
with Professor Trash Wheel. The column names are: `dumpster` (unique
dumpster number), `month`,`year`, and `date` of trash collection,
`weight_in_tons` of trash collected, `volume_in_cubic_yards` of trash
collected, `plastic_bottles` (number?), `polystyrene` (presumably number
of items), `cigarette_butts`, `glass_bottles`, `grocery_bags`,
`chips_bags`, and `sports_balls` all in numbers, `homes_powered` from
the energy generated through trash conversion, and a final `identifier`
column for easy distinction between the Mr. Trash Wheel and Professor
Trash Wheel data in the trash_wheel_collective data.

-   The total weight of trash collected by Professor Trash Wheel was:
    190.12 tons.
-   The total number of sports balls collected by Mr. Trash Wheel in
    2020 was: 856

# Problem 2: FiveThirtyEight - Hack Your Way To Scientific Glory

``` r
politician_data = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = recode(month, "01" = "january", "02" = "february", "03" = "march", "04" = "april", 
                        "05" = "may", "06" = "june", "07" = "july", "08" = "august", "09" = "september",
                        "10" = "october", "11" = "november", "12" = "december")) %>%
  mutate(president = recode(prez_dem, "0" = "gop", "1" = "dem")) %>%
  select(-prez_dem, -prez_gop, -day) %>%
  select(year, month, president, everything())
```

In the cleaning process above, I used the `prez_dem` column to code for
the newly-made `president` column as this enabled a simple set up of
associating ‘0’ with gop and ‘1’ with dem. The `prez_gop` column was not
used for this process as it contained an additional value of 2 within
rows pertaining to 15/08/74 - 15/12/74. Upon reading, I have learned
that this was the time period when Republican VP Ford was declared
President as the existing Republican president Nixon was forced to
resign due to the Watergate Scandal. In terms of my decision to code for
the `president` colum via the `prez_dem` column, this adds up as the
associated time would rightly be identified as `gop` as both Nixon and
Ford were Republicans.

``` r
stock_data =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(year = as.numeric(year)) %>%
  mutate(year = case_when(year < 50 ~ 2000 + year,
                          year >= 50 ~ 1900 + year)) %>%
  mutate(year = as.character(year)) %>%
  mutate(month = as.numeric(month)) %>%
  arrange(year, month) %>%
  mutate(month = recode(month, "1" = "january", "2" = "february", "3" = "march", "4" = "april", 
                        "5" = "may", "6" = "june", "7" = "july", "8" = "august", "9" = "september",
                        "10" = "october", "11" = "november", "12" = "december")) %>%
  rename(snp_closing_value = close) %>%
  select(year, month, everything())
```

``` r
unemployment_data = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  mutate(year = as.character(year)) %>%
  pivot_longer(jan:dec, names_to = "month", values_to = "unemp_%_per_month") %>%
  mutate(month = recode(month, "jan" = "january", "feb" = "february", "mar" = "march", "apr" = "april", 
                        "may" = "may", "jun" = "june", "jul" = "july", "aug" = "august", 
                        "sep" = "september", "oct" = "october", "nov" = "november", "dec" = "december"))
```

``` r
pols_snp = inner_join(politician_data, stock_data, by = c("year", "month"))
#As the day column from the snp sheet becomes somewhat irrelevant in the larger scheme of this situation, I will remove it: 
pols_snp = select(pols_snp, -day)
```

``` r
pols_snp_unemp = left_join(pols_snp, unemployment_data, by = c("year", "month"))
```

-   Upon tidying, the `pols` dataset which I initially refer to as the
    `politician data` consists of **822 rows of observations and 9
    columns**. These columns are: *‘year, month, president, gov_gop,
    sen_gop, rep_gop, gov_dem, sen_dem, rep_dem’*. Starting from **1947
    January** and going on upto **2015 June**, this data essentially
    provides monthly information on the constitutional make-up (number
    of governors, senators, and representatives - all either Republican
    or Democratic) of the ruling-government.

-   Upon tidying, the `snp` dataset which I initially refer to as the
    `stock data` consists of **787 rows of observations and 4 columns**.
    These columns are: *‘year, month, day, snp_closing_value’*. This
    data entails the closing values of the S&P stock index on a monthly
    manner from **1950 January** to **2015 July**.

-   Upon tidying, the `unemployment` dataset which I initially refer to
    as the `unemployment data` consists of **816 rows of observations
    and 3 columns**. These columns are: *’year, month,
    unemp*%*per_month’*. This data provides information on the
    percentage of unemployment per month from **1948 January** to **2015
    June**.

For the joins, I first performed an `inner_join` while connecting the
stock data to the politician data. As the stock data only begins from
1950 January and goes on every month till 2015 July while politician
data begins from 1947 January and goes on every month till 2015 June, it
seemed meaningful to perform an inner join and attach the overlapping
months given the potential purpose of analysing trends between the
governmental make-up and the stock closing values. As a result, the
`pols_snp` dataset has **786 rows of observations and 10 columns**. The
p`pols_snp` data ranges from 1950 January to 2015 June. The unemployment
data contains 6 rows at the end with no associated percentage values;
these were excluded in the process of performing a `left_join` of this
onto the `pols_snp` for the creation of `pols_snp_unemp` dataset. This
dataset has **786 rows of observations and 11 columns**. As the
unemployment data ranges from 1948 January to 2015 June (exluding the
last few rows with no percentage values), and the `pols_snp` data ranges
from 1950 January to 2015 June, the left join was performed to retain
all the overlapping information on the basis of the smaller-sized
`pols-snp` data. As a result, there are the same 786 rows as in the
`pols_snp` set but an additional column consisting of unemployment
rates. This dataset contains information from 2015 January to 2015 June.
