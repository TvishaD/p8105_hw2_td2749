---
title: "p8105_hw2_td2749"
author: "Tvisha R. Devavarapu"
date: "2022-09-29"
output: github_document
---

```{r Setting up tidyverse, message = FALSE}
library(tidyverse)
```

## Problem 1: NYC Transit Data (Practice)

```{r Setting Up}
nyc_transit = 
  read_csv("data/nyc_transit.csv",
           col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), 
         entry, exit_only, vending, entrance_type, ada) %>%
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As is, there are 1868 observations across 20 variables. The data is not fully tidy. The route number colums could be made into a single route variable (pivot long). 

```{r Identifying Unique Stations}
nyc_transit %>% 
  select(station_name, line) %>% 
  distinct
```

There are 465 unique stations. 

```{r ADA Compliance}
nyc_transit %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

84 stations are ADA Compliant. 

```{r Entrance/Exit Proportions and Vending}
nyc_transit %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Mean = 0.377

```{r A Train and ADA Compliance}
nyc_transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

nyc_transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

17

# Problem 2: Trash Wheel
The original Mr. Trash Wheel excel sheet consists of 550 rows and 14 columns. Upon examination of the entire 'Mr. Trash Wheel' sheet in the newly updated file, I have realized that the required data is listed in continuous rows with no unnecessary breaks that would hinder the generation of a tidy/analysis-friendly sheet. Hence, I excluded the first row (image) and last row (totals) of the original sheet, which leaves us 548 rows including the first row with variable names. The resultant sheet has 547 dumpster-specific rows and 15 columns of variables (the last one is the identifier I have generated for the binding purpose. (Note: I removed the drop_na(Dumpster) component which was relevant for the earlier data set. As it is not serving any purpose here due to lack of empty cells in the 'dumpster' column, I have deleted it from the current code.)

```{r Mr. Trash Wheel}
mr_trash_wheel = 
  readxl::read_excel("data/new_t_w.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N549") %>%
  janitor::clean_names() %>%
  rename(weight_in_tons = weight_tons, volume_in_cubic_yards = volume_cubic_yards) %>%
  mutate(sports_balls = as.integer(round(sports_balls)))

mr_trash_wheel = mutate(mr_trash_wheel, identifier = rep("*", nrow(mr_trash_wheel)))
```

```{r Professor Trash Wheel}
prof_trash_wheel = 
  readxl::read_excel("data/new_t_w.xlsx", sheet = "Professor Trash Wheel", range = "A2:M96") %>%
  janitor::clean_names() %>%
  rename(weight_in_tons = weight_tons, volume_in_cubic_yards = volume_cubic_yards) %>%
  mutate(year = as.character(year))

prof_trash_wheel = mutate(prof_trash_wheel, identifier = rep("#", nrow(prof_trash_wheel)))

```

```{r Binding Mr. Trash Wheel and Professor Trash Wheel}
trash_wheel_collective = 
  bind_rows(mr_trash_wheel, prof_trash_wheel)
```

The final dataset `trash_wheel_collective` consists of *641 observations* ranging across *15 columns*. 547 of the observations pertain to unique dumpsters associated with Mr. Trash Wheel. The remaining 94 observations pertain to the unique dumpsters associated with Professor Trash Wheel. The column names are: `dumpster` (unique dumpster number), `month`,`year`, and `date` of trash collection, `weight_in_tons` of trash collected, `volume_in_cubic_yards` of trash collected, `plastic_bottles` (number?), `polystyrene` (presumably number of items), `cigarette_butts`, `glass_bottles`, `grocery_bags`, `chips_bags`, and `sports_balls` all in numbers, `homes_powered` from the energy generated through trash conversion, and a final `identifier` column for easy distinction between the Mr. Trash Wheel and Professor Trash Wheel data in the trash_wheel_collective data.

* The total weight of trash collected by Professor Trash Wheel was: `r with(trash_wheel_collective, sum(weight_in_tons[identifier == "#"]))` tons. 
* The total number of sports balls collected by Mr. Trash Wheel in 2020 was: `r with(trash_wheel_collective, sum(sports_balls[year == 2020 & identifier == '*']))`


# Problem 2: FiveThirtyEight - Hack Your Way To Scientific Glory

```{r Setting up "pols-month" data, message = FALSE}
politician_data = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = recode(month, "01" = "january", "02" = "february", "03" = "march", "04" = "april", 
                        "05" = "may", "06" = "june", "07" = "july", "08" = "august", "09" = "september",
                        "10" = "october", "11" = "november", "12" = "december")) %>%
  mutate(president = recode(prez_dem, "0" = "gop", "1" = "dem")) %>%
  select(-prez_dem, -prez_gop, -day) %>%
  select(year, month, president, everything())
```
In the cleaning process above, I used the `prez_dem` column to code for the newly-made `president` column as this enabled a simple set up of associating '0' with gop and '1' with dem. The `prez_gop` column was not used for this process as it contained an additional value of 2 within rows pertaining to 15/08/74 - 15/12/74. Upon reading, I have learned that this was the time period when Republican VP Ford was declared President as the existing Republican president Nixon was forced to resign due to the Watergate Scandal. In terms of my decision to code for the `president` colum via the `prez_dem` column, this adds up as the associated time would rightly be identified as `gop` as both Nixon and Ford were Republicans.


```{r Setting up "snp" data, message = FALSE}
stock_data =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate(year = as.numeric(year)) %>%
  mutate(year = case_when(year < 50 ~ 2000 + year,
                          year >= 50 ~ 1900 + year)) %>%
  mutate(year = as.character(year)) %>%
  mutate(month = as.numeric(month)) %>%
  arrange(year, month) %>%
  mutate(month = recode(month, "1" = "january", "2" = "february", "3" = "march", "4" = "april", 
                        "5" = "may", "6" = "june", "7" = "july", "8" = "august", "9" = "september",
                        "10" = "october", "11" = "november", "12" = "december")) %>%
  rename(snp_closing_value = close) %>%
  select(year, month, everything())
```

```{r Setting up "unemployment" data, message = FALSE}
unemployment_data = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  mutate(year = as.character(year)) %>%
  pivot_longer(jan:dec, names_to = "month", values_to = "unemp_%_per_month") %>%
  mutate(month = recode(month, "jan" = "january", "feb" = "february", "mar" = "march", "apr" = "april", 
                        "may" = "may", "jun" = "june", "jul" = "july", "aug" = "august", 
                        "sep" = "september", "oct" = "october", "nov" = "november", "dec" = "december"))
```

```{r Joining pols and snp}
pols_snp = inner_join(politician_data, stock_data, by = c("year", "month"))
#As the day column from the snp sheet becomes somewhat irrelevant in the larger scheme of this situation, I will remove it: 
pols_snp = select(pols_snp, -day)
```

```{r Joining pols+snp with unemployment}
pols_snp_unemp = left_join(pols_snp, unemployment_data, by = c("year", "month"))
```


* Upon tidying, the `pols` dataset which I initially refer to as the `politician data` consists of **`r nrow(politician_data)` rows of observations and `r ncol(politician_data)` columns**. These columns are:  _'`r colnames(politician_data)`'_. Starting from **1947 January** and going on upto **2015 June**, this data essentially provides monthly information on the constitutional make-up (number of governors, senators, and representatives - all either Republican or Democratic) of the ruling-government.

* Upon tidying, the `snp` dataset which I initially refer to as the `stock data` consists of **`r nrow(stock_data)` rows of observations and `r ncol(stock_data)` columns**. These columns are:  _'`r colnames(stock_data)`'_. This data entails the closing values of the S&P stock index on a monthly manner from **1950 January** to **2015 July**. 

* Upon tidying, the `unemployment` dataset which I initially refer to as the `unemployment data` consists of **`r nrow(unemployment_data)` rows of observations and `r ncol(unemployment_data)` columns**. These columns are:  _'`r colnames(unemployment_data)`'_. This data provides information on the percentage of unemployment per month from **1948 January** to **2015 June**. 


For the joins, I first performed an `inner_join` while connecting the stock data to the politician data. As the stock data only begins from 1950 January and goes on every month till 2015 July while politician data begins from 1947 January and goes on every month till 2015 June, it seemed meaningful to perform an inner join and attach the overlapping months given the potential purpose of analysing trends between the governmental make-up and the stock closing values. As a result, the `pols_snp` dataset has **`r nrow(pols_snp)` rows of observations and `r ncol(pols_snp)` columns**. The p`pols_snp` data ranges from 1950 January to 2015 June. 
The unemployment data contains 6 rows at the end with no associated percentage values; these were excluded in the process of performing a `left_join` of this onto the `pols_snp` for the creation of `pols_snp_unemp` dataset. This dataset has **`r nrow(pols_snp_unemp)` rows of observations and `r ncol(pols_snp_unemp)` columns**. As the unemployment data ranges from 1948 January to 2015 June (exluding the last few rows with no percentage values), and the `pols_snp` data ranges from 1950 January to 2015 June, the left join was performed to retain all the overlapping information on the basis of the smaller-sized `pols-snp` data. As a result, there are the same `r nrow(pols_snp_unemp)` rows as in the `pols_snp` set but an additional column consisting of unemployment rates. This dataset contains information from 2015 January to 2015 June. 